# 分布式原理补充





## `RPC`

其他的内容参考课程的pdf。



这里补充两个不错的文章：

* [深入浅出 RPC - 浅出篇](https://blog.csdn.net/mindfloating/article/details/39473807)

* [深入浅出 RPC - 深入篇](https://blog.csdn.net/mindfloating/article/details/39474123)

其中将`rpc`调用流程中涉及的组件、自定义`rpc`协议需要考虑的问题都做了介绍。







## `PAXOS` 算法



### 什么是`paxos`算法

**Paxos算法**是[莱斯利·兰伯特](https://zh.wikipedia.org/wiki/莱斯利·兰伯特)（英语：Leslie Lamport，[LaTeX](https://zh.wikipedia.org/wiki/LaTeX)中的“La”）于1990年提出的一种基于消息传递且具有高度容错特性的共识（consensus）算法。



### `paxos`算法解决的问题

首先`paxos`不是一致性（consistency）算法，而是共识（consensus）算法

分布式系统中的节点通信存在两种模型：[共享内存](https://zh.wikipedia.org/wiki/共享内存)（Shared memory）和[消息传递](https://zh.wikipedia.org/wiki/消息传递)（Messages passing）。基于消息传递通信模型的分布式系统，不可避免的会发生以下错误：进程可能会慢、被杀死或者重启，消息可能会延迟、丢失、重复，在基础 Paxos 场景中，先不考虑可能出现消息篡改即[拜占庭错误](https://zh.wikipedia.org/wiki/拜占庭将军问题)的情况。**Paxos 算法解决的问题是在一个可能发生上述异常的[分布式系统](https://zh.wikipedia.org/wiki/分布式计算)中如何就某个值达成一致，保证不论发生以上任何异常，都不会破坏决议的共识。**

简单来讲就是：解决了分布式系统一致性问题



### 概念和推导

这部分看看课程中的《分布式原理》，以及看看维基百科：[Paxos算法]([https://zh.wikipedia.org/wiki/Paxos%E7%AE%97%E6%B3%95](https://zh.wikipedia.org/wiki/Paxos算法))（讲的很好）







### paxos算法的内容

通过一个决议分为两个阶段：

1. prepare阶段：
   1. proposer选择一个提案编号n并将prepare请求发送给acceptors中的一个多数派；
   2. acceptor收到prepare消息后，如果提案的编号大于它已经回复的所有prepare消息(回复消息表示接受accept)，则acceptor将自己上次接受的提案回复给proposer，并承诺不再回复小于n的提案；
2. 批准阶段：
   1. 当一个proposer收到了多数acceptors对prepare的回复后，就进入批准阶段。它要向回复prepare请求的acceptors发送accept请求，包括编号n和根据P2c决定的value（如果根据P2c没有已经接受的value，那么它可以自由决定value）。
   2. 在不违背自己向其他proposer的承诺的前提下，acceptor收到accept请求后即批准这个请求。

这个过程在任何时候中断都可以保证正确性。例如如果一个proposer发现已经有其他proposers提出了编号更高的提案，则有必要中断这个过程。因此为了优化，在上述prepare过程中，如果一个acceptor发现存在一个更高编号的提案，则需要通知proposer，提醒其中断这次提案。

![image-20200701113534395](img/分布式原理/image-20200701113534395.png)



### paxos的活锁（失活）

两个`proposer`（提案）在`prepare`阶段，互相争抢，不断将提案编号变大，陷入死循环时就会出现活锁。



一般活锁可以通过 **随机睡眠-重试** 的方法解决。这种情况下的解决方案是选举出一个leader，仅允许leader提出提案。但是由于消息传递的不确定性，可能有多个proposer自认为自己已经成为leader。Lamport在[The Part-Time Parliament](http://research.microsoft.com/users/lamport/pubs/lamport-paxos.pdf)一文中描述并解决了这个问题。







### 提案达到共识的流程图解



![image-20200630173305670](img/分布式原理/image-20200630173305670.png)





### `paxos`学习时的一些疑问



**1. 如果proposer的数量和acceptor的数量一致，且proposer提交的提案和acceptor一一对应，那么就都完了？？**

这个问题用：一个提案必须被半数以上的acceptor来规避



**2.这些规则（p2c、p2b、p2a、p2）由谁来保证？**

`paxos`是算法理论，`p2c、p2b`这些是推导过程，所以具体的保证是`paxos`的实现来做。



**3. `paxos`是为了解决分布式系统因为网络延迟、服务宕机等情况导致的数据不一致问题，多个副本结点想要修改同一个数据状态的算法。A结点想将数据状态改为1，B想改为2，那么按`paxos`的算法，只会有一个设定成功。那么另一个就被舍弃了？那么生产中，应该舍弃的是中间数据，这里的舍弃是不是太随机了？（谁先prepare好就是谁）**

不会，`paxos`选举提案分为两个过程：`prepare`和`accept`。在`prepare`过程中，可以理解为“谁得到多数票，谁可以发送`accept`请求”。发送实际`value`的过程在`accept`阶段，即使A在本次`paxos`中获胜了，B的值也不会丢失，而是下次`paxos`流程中再去和其他的`proposer`的提案一起竞争。

这里要明确，`paxos`保证的是分布式环境下多个角色执行提案顺序是一样的。打个比方：

客户端发来一个请求给5个节点（A、B、C、D、E）的分布式系统，这个请求会要求修改3条数据。

为了达成数据一致性，5个节点间会进行数据同步。比如请求到的是A，A发现更新3条数据需要执行3个命令，顺序是`[op1,op2,op3]`，然后它广播给其他几个节点（通知方式不仔细考虑），其他节点要想大家执行命令序列后数据是一样的，那么`[op1,op2,op3]`中的操作顺序一定不能改变。

这时候`paxos`就用来保证5个节点每次都执行一样的命令，都执行`op1`或者`op2`或者`op3`，不会出现A执行`op1`，B在执行`op2`这种情况。

至于`[op1,op2,op3]`命令的顺序则不是`paxos`来保证，由发出请求的地方来保证。这里就是A节点。它会先发送`op1`提案，再发送`op2`提案。